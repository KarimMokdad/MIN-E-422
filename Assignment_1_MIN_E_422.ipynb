{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aOWM6VHVwtjf"
   },
   "source": [
    "**Load the Required Libraries**\n",
    "\n",
    "The following code loads the required libraries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hwGN4mFDwu4e"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from google.colab.patches import cv2_imshow\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xb5rnP3AxShG"
   },
   "source": [
    "If you get a package import error, you may have to first install some of these packages. This can usually be accomplished by typing '!pip install [package-name]'. More assistance is available with the respective package docs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_8WiYnBB4Wr_"
   },
   "outputs": [],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LhmYWFw1v6kA"
   },
   "source": [
    "**ACCESSING FILES**\n",
    "\n",
    "Since Google Colab uses a cloud service, it does not have access to your cloud driver. The program below lets you access your drive. Run the code, click the link, and then paste the code you get inside the input. The path will be “/content/gdrive/”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fAgfrlbawlIf",
    "outputId": "36617c03-e80d-4428-d970-270e7697d844"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"gdrive\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lqrf0R8MyFD1"
   },
   "source": [
    "**Set the working directory**\n",
    "\n",
    "I always like to do this so I don't lose the location of the files and to simplify subsequent read and writes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BklNJdu0wlsv"
   },
   "outputs": [],
   "source": [
    "!mkdir Assignment_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gNJSUNujzA2T"
   },
   "source": [
    "**Create the necessary folders to organize input and output data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TFRQYWm8zM2C"
   },
   "outputs": [],
   "source": [
    "os.makedirs('/content/Assignment_1/Video') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lzMPmm_yzzfq"
   },
   "outputs": [],
   "source": [
    "os.makedirs('/content/Assignment_1/yolo_data') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sel-RoRVzypr"
   },
   "outputs": [],
   "source": [
    "os.makedirs('/content/Assignment_1/Images_from_video') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gBGR52C80ZO7"
   },
   "source": [
    "**CONVERTING VIDEO FILE TO IMAGES**\n",
    "\n",
    "In Google Colab, live capturing from cameras are disabled, so we will just process the program using images instead. First, we need to use the function ‘cv.VideoCapture()’ with the parameters being the path to the file. Now we will take a frame of that video using the function ‘capture.read()’ and save it to the directory (in this case it will be saved under “/content/Assignment_1/Images_from_video”)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xqutgZGf0cjp"
   },
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "from google.colab.patches import cv2_imshow\n",
    "capture = cv.VideoCapture(\"//content/Assignment_1/Video/Pexels Videos 1393766.mp4\")\n",
    "isTrue, frame = capture.read()\n",
    "count = 0\n",
    "while isTrue:\n",
    "  isTrue, frame = capture.read()\n",
    "  if not isTrue:\n",
    "    break\n",
    "  cv.imwrite(\"/content/Assignment_1/Images_from_video/frame%03d.jpg\" %count, frame)\n",
    "  count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rxUVRktX1af3"
   },
   "source": [
    "**IMPORT OUR CLASS IDS**\n",
    "\n",
    "Next is to import the file that will be consisting of our weights, config, and names. Since we are using YOLO3, we will be using the coco set consisting of 80 common objects like “person”, “cup”, “cell phone”, etc. The weights themselves are indexed and do not have a name associated with that index, so we will be making that below.\n",
    "\n",
    "We will first open the text file name ‘coco.names’ using ‘with open() as f’ with the first parameter being the file name and the second parameter being the read type. The variable ‘classNames’ will store a list consisting of the names in the correct index. ‘f.read()’ just reads the whole file as a string, then ‘.split’ splits the string into a list separated by the newline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HohCKPL41kFO"
   },
   "outputs": [],
   "source": [
    "importClassNames = \"/content/Assignment_1/yolo_data/coco.names\"\n",
    "classNames = []\n",
    "with open(importClassNames, \"r\") as f: \n",
    "    classNames = f.read().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uzQiHof-3wnA"
   },
   "source": [
    "If I were to print the output of ‘classNames’ after running this code, I get an output looking like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gIkKApRO2Kkv"
   },
   "outputs": [],
   "source": [
    "classNames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UEVUn56W32kX"
   },
   "source": [
    "Next, we will create the machine learning algorithm using the two files found on this website. The machine-learning algorithm uses a deep neural network (dnn). We will be using the variable ‘net’ later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f7mNjmj233Km"
   },
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "modelConfiguation = \"/content/Assignment_1/yolo_data/yolov3.cfg\" \n",
    "modelWeights = \"/content/Assignment_1/yolo_data/yolov3.weights\"  \n",
    "net = cv.dnn.readNet(modelConfiguation, modelWeights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5WPEdymd4ibX"
   },
   "source": [
    "**CONVERTING ‘FRAME’ TO BE USED IN THE ALGORITHM**\n",
    "\n",
    "Right now the picture cannot be processed in the machine learning algorithm, So we will convert the frame into something called a ‘blob’. ‘cv.dnn.blobFromImage()’ takes in a few parameters: image, scale factor, size, mean, swap RB, crop.\n",
    "\n",
    "\n",
    "We will then send the input of the blob into the network. The ‘layerNames’ variable gets all the variable names of our layers in the network.\n",
    "Next, we have to extract the output layers using the function ‘network.getUnconnectedOutlayers()’. Note that we are just getting the index of the output, so we will use the index and refer it back to the ‘layerNames’. Since the network does not use the index ‘0’ and starts the index at ‘1’, and our output names start at ‘0’, we will shift the index by ‘-1’.\n",
    "Next, we will make a variable called ‘outputs’ that forwards the ‘outputNames’ to the network using the function ‘net.forward’.\n",
    "Now the network has a bunch of values including the bounding box, as well as its percentages, so the next part of the programs start filtering those results to be displayed later.\n",
    "\n",
    "\n",
    "Outputs will be the results we will need to display results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "um7UFcdQ4ojW"
   },
   "outputs": [],
   "source": [
    "def getOutputs(frame):\n",
    "    blob = cv.dnn.blobFromImage(frame, 1/255, # ---> \n",
    "          (widthheight, widthheight), [0, 0, 0], 1, crop = False)\n",
    "    net.setInput(blob)\n",
    "    layerNames = net.getLayerNames() \n",
    "    outputNames = [layerNames[i[0] - 1] # ---> \n",
    "          for i in net.getUnconnectedOutLayers()]\n",
    "    outputs = net.forward(outputNames) \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q56HVTRw5LHW"
   },
   "source": [
    "**CREATING WHAT TO BE DISPLAYED**\n",
    "\n",
    "Now that we have the results, we will now make an algorithm to display the highest probability of that object in the bounding box. First, note that the output consists of 85 values instead of 80 from our name list. The first 5 values are as followed: center x, center y, width, height, confidence object present. The rest of the 80 values are the probability of that object displayed. We will make a new variable ‘scores‘ consisting of only the probability of those objects. We will then get the ‘classID’ of the max probability of that object. We will also get that probability value by finding the index of the scores and put it in ‘confidence’.\n",
    "\n",
    "The next thing is to check if the probability of that object is higher than our threshold. If it is we will make a bounding box for it and append the confidence value and class ID to our lists. To make a bounding box, we will need 4 variables: x and y coordinates, the width, and the height of the bounding box. The code below edits the center x and y coordinate to the respective coordinate.\n",
    "\n",
    "The variable ‘outputBox’ removes unnecessary boxes, and this is controlled by the variable ‘nmsThreshold’. We will finally display the boxes to the window using ‘cv.rectangle()’, ‘cv.putText()’, as shown below iterating through ‘outputBox’. ‘cv.rectangle()’ takes in the image, first coordinate, second coordinate, color, and the thickness. ‘cv.putText()’ has a few parameters like the image, displayed text, coordinate, font, font size, color, thickness. We have calculated the coordinates for the boxes to be displayed from the bounding boxes, and the displayed text from the other lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4QdZGpM85ESV"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def displayBox(outputs):\n",
    "    height, width, channels = frame.shape  \n",
    "    boundingBox = []   \n",
    "    classIDs = []      \n",
    "    confidenceValues = []   \n",
    "    for output in outputs:\n",
    "        for values in output:  \n",
    "            scores = values[5:] \n",
    "            classID = np.argmax(scores)  \n",
    "            confidence = scores[classID] \n",
    "            if confidence > confidenceThreshold:  \n",
    "                w, h = int(values[2] * width), int(values[3] * height) \n",
    "                x, y = int(values[0] * width - w/2),int(values[1] * height - h/2)  \n",
    "                boundingBox.append([x, y, w, h])  \n",
    "                classIDs.append(classID) \n",
    "                confidenceValues.append(float(confidence)) \n",
    "    outputBox = cv.dnn.NMSBoxes(boundingBox, confidenceValues,confidenceThreshold, nmsThreshold)\n",
    "    for i in outputBox:\n",
    "        index = i[0]\n",
    "        color = colors[classIDs[index]]\n",
    "        x, y, w, h = boundingBox[index][:4]\n",
    "        cv.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n",
    "        label = str(classNames[classIDs[index]].capitalize()) + \" \" + str(int(confidenceValues[index] * 100)) + \" %\"\n",
    "        cv.putText(frame, label,(x + 5, y + 16), font, 0.5, color, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r2ULo81Y5gcn"
   },
   "source": [
    "**MAIN FUNCTION**\n",
    "\n",
    "We will first list off all of our constants here. This is so that we can easily change it later. We will now get all the files using the path ‘/content/’ followed by ‘*.*’ to get all the files in that directory. We will sort them in order of the frame number and now display the file name and the picture with the algorithm for all the frames.\n",
    "\n",
    "The function ‘glob.glob()‘ gets an unsorted file list of that path directory.\n",
    "‘Sorted()’ sorts the list into a sorted list by the time the file was made, which is the same as ordering them by number. The ‘frameSize’ is the size of ‘frame’ being used in the network. If this value is smaller, it will take less time for the frame to be processed, sacrificing accuracy. Inside the for loop, I have used “.strip()”. This basically strips the string from the inputted string. In this case, it just removes “/content/” and outputs just the file name. “cv.imread()” captures the image of the file. ‘cv.resize()’ resizes the frame. ‘displayBox()’ and ‘getOuputs‘ are the two functions we have implemented above. ‘cv2_imshow()’ displays the image onto the output. This is the replacement of ‘cv2.imshow()’ since it is disabled in Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "fQLaStOo5U51",
    "outputId": "db859d3a-b6c7-4cb6-baa2-f757f9f767e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from google.colab.patches import cv2_imshow\n",
    "import glob\n",
    "import os\n",
    "widthheight = 320             \n",
    "confidenceThreshold = 0.5     \n",
    "nmsThreshold = 0.6            \n",
    "font = cv.FONT_HERSHEY_SIMPLEX\n",
    "colors = np.random.uniform(0, 255, size = (len(classNames),3)) \n",
    "path = \"/content/Assignment_1/Images_from_video/\"\n",
    "pathFile = path + \"*.*\"                                    \n",
    "files = sorted(glob.glob(pathFile), key = os.path.getmtime)  \n",
    "frameSize = 0.3 \n",
    "for f in files:\n",
    "    print(f.strip(path))  \n",
    "    frame = cv.imread(f)  \n",
    "    frame = cv.resize(frame, None, fx = frameSize , fy = frameSize) \n",
    "    displayBox(getOutputs(frame))\n",
    "    cv2_imshow(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sSlH3yMI5ozW"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Assignment 1 - MIN E 422.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
